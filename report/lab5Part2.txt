# ğŸ§  Lab 5 â€“ Text Classification using RNN/LSTM

---
File notebook :Untitled37.ipynb
## **1. Tá»•ng quan & Má»¥c tiÃªu**
BÃ i lab nÃ y táº­p trung vÃ o bÃ i toÃ¡n **phÃ¢n loáº¡i vÄƒn báº£n (text classification)** â€” cá»¥ thá»ƒ lÃ  xÃ¡c Ä‘á»‹nh **Ã½ Ä‘á»‹nh (intent)** cá»§a cÃ¢u truy váº¥n.  
Má»¥c tiÃªu:
- So sÃ¡nh hiá»‡u nÄƒng giá»¯a cÃ¡c mÃ´ hÃ¬nh truyá»n thá»‘ng (TF-IDF, Word2Vec) vÃ  mÃ´ hÃ¬nh há»c sÃ¢u tuáº§n tá»± (LSTM).  
- PhÃ¢n tÃ­ch Æ°u nhÆ°á»£c Ä‘iá»ƒm, kháº£ nÄƒng tá»•ng quÃ¡t hÃ³a vÃ  tÃ­nh hiá»‡u quáº£ trÃªn dá»¯ liá»‡u nhá».  
- ÄÆ°a ra nháº­n xÃ©t Ä‘á»‹nh lÆ°á»£ng (F1-score, loss) vÃ  Ä‘á»‹nh tÃ­nh (case study).  

---

## **2. Dá»¯ liá»‡u vÃ  xá»­ lÃ½ trÆ°á»›c**
- Dá»¯ liá»‡u ká»³ vá»ng: `hwu_train.tsv`, `hwu_val.tsv`, `hwu_test.tsv`.  
  Do khÃ´ng cÃ³ file tháº­t, má»™t **táº­p dá»¯ liá»‡u mÃ´ phá»ng** Ä‘Æ°á»£c táº¡o gá»“m:
  - 8 máº«u huáº¥n luyá»‡n  
  - 8 máº«u validation  
  - 8 máº«u kiá»ƒm thá»­  
  - 6 lá»›p (intents): `flight_book`, `weather_query`, `reminder_create`, `home_automation`, `alarm_cancel`, `music_play`.

### **Tiá»n xá»­ lÃ½:**
- Chuáº©n hÃ³a vÄƒn báº£n: lowercase, bá» kÃ½ tá»± Ä‘áº·c biá»‡t.  
- Tokenization báº±ng Keras Tokenizer.  
- Padding Ä‘á»™ dÃ i cá»‘ Ä‘á»‹nh 15.  
- Chia train/val/test vá»›i stratify theo lá»›p.  

MÃ´i trÆ°á»ng thá»±c nghiá»‡m:
- **TensorFlow 2.19.1**
- **scikit-learn 1.5.2**
- **Gensim 4.3.3**
- **NumPy 1.26.4**, **SciPy 1.11.4**

---

## **3. MÃ´ hÃ¬nh vÃ  pipeline**
### **Pipeline 1 â€” TF-IDF + Logistic Regression**
- Biá»ƒu diá»…n: TF-IDF (1â€“2 n-grams, 10.000 Ä‘áº·c trÆ°ng).  
- Bá»™ phÃ¢n loáº¡i: Logistic Regression (C=2.0).  

### **Pipeline 2 â€” Word2Vec (Average) + Dense**
- Huáº¥n luyá»‡n Word2Vec tá»« train+val (`vector_size=100`, `window=5`).  
- Trung bÃ¬nh vector tá»« trong cÃ¢u â†’ Dense(128, ReLU) â†’ Softmax.  

### **Pipeline 3 â€” Pretrained Word2Vec + LSTM**
- Ma tráº­n embedding khá»Ÿi táº¡o tá»« Word2Vec huáº¥n luyá»‡n trÆ°á»›c.  
- Kiáº¿n trÃºc: `Embedding (frozen)` â†’ `LSTM(128)` â†’ `Dense(softmax)`.  

### **Pipeline 4 â€” Embedding (Scratch) + LSTM**
- `Embedding` khá»Ÿi táº¡o ngáº«u nhiÃªn vÃ  Ä‘Æ°á»£c huáº¥n luyá»‡n cÃ¹ng LSTM(128).  

---

## **4. Káº¿t quáº£ Ä‘á»‹nh lÆ°á»£ng**

| Pipeline | Macro-F1 (Test) | Nháº­n xÃ©t ngáº¯n |
|-----------|----------------|---------------|
| **TF-IDF + LR** | **1.0000** | Hoáº¡t Ä‘á»™ng tá»‘t nháº¥t; phÃ¹ há»£p dá»¯ liá»‡u nhá», tuyáº¿n tÃ­nh dá»… phÃ¢n tÃ¡ch. |
| **W2V-Avg + Dense** | 0.2286 | Máº¥t cáº¥u trÃºc chuá»—i, thÃ´ng tin ngá»¯ cáº£nh yáº¿u. |
| **Emb (Pretrained W2V) + LSTM** | 0.0667 | KhÃ´ng há»c Ä‘Æ°á»£c do dá»¯ liá»‡u quÃ¡ Ã­t. |
| **Emb (Scratch) + LSTM** | 0.0667 | Gáº§n nhÆ° ngáº«u nhiÃªn; cáº§n dá»¯ liá»‡u lá»›n hÆ¡n Ä‘á»ƒ há»™i tá»¥. |

**Nháº­n xÃ©t:**  
TF-IDF + LR Ä‘áº¡t káº¿t quáº£ vÆ°á»£t trá»™i nhá» dá»¯ liá»‡u nhá», tá»« khÃ³a rÃµ rÃ ng.  
CÃ¡c mÃ´ hÃ¬nh tuáº§n tá»± (LSTM) khÃ´ng Ä‘á»§ dá»¯ liá»‡u Ä‘á»ƒ há»c má»‘i quan há»‡ tá»« xa (long-term dependency).  

---

## **5. PhÃ¢n tÃ­ch Ä‘á»‹nh tÃ­nh**

| CÃ¢u vÃ­ dá»¥ | NhÃ£n tháº­t | Dá»± Ä‘oÃ¡n (LSTM) | Nháº­n xÃ©t |
|------------|------------|----------------|-----------|
| â€œbook a flight from hanoi to danangâ€ | `flight_book` | `weather_query` | LSTM khÃ´ng hiá»ƒu Ä‘Æ°á»£c ngá»¯ cáº£nh â€œflightâ€. |
| â€œis it going to rain in hanoi tomorrowâ€ | `weather_query` | `weather_query` | TF-IDF nháº­n Ä‘Ãºng nhá» tá»« khÃ³a â€œrainâ€, LSTM chá»‰ Ä‘Ãºng ngáº«u nhiÃªn. |

**Káº¿t luáº­n Ä‘á»‹nh tÃ­nh:**  
TF-IDF dÃ¹ng Ä‘áº·c trÆ°ng tÄ©nh, dá»… há»c khi táº­p nhá».  
LSTM cáº§n dá»¯ liá»‡u lá»›n Ä‘á»ƒ há»c Ä‘Æ°á»£c phá»¥ thuá»™c dÃ i trong chuá»—i (long-term dependency).  

---

## **6. Tháº£o luáº­n (Discussion)**
Trong thá»±c táº¿, cÃ¡c máº¡ng tuáº§n tá»± nhÆ° **LSTM** cÃ³ Æ°u tháº¿ rÃµ khi:
- Dá»¯ liá»‡u lá»›n, cÃ³ cáº¥u trÃºc ngá»¯ cáº£nh phá»©c táº¡p.  
- Quan há»‡ giá»¯a cÃ¡c tá»« mang tÃ­nh thá»© tá»±, vÃ­ dá»¥: *â€œnot goodâ€* vs *â€œgoodâ€*.  

Tuy nhiÃªn, trong thÃ­ nghiá»‡m nÃ y:
- Dá»¯ liá»‡u nhá» â†’ gradient khÃ´ng á»•n Ä‘á»‹nh â†’ mÃ´ hÃ¬nh khÃ´ng há»™i tá»¥.  
- Táº­p cÃ³ nhiá»u lá»›p nhÆ°ng Ã­t máº«u má»—i lá»›p â†’ máº¥t cÃ¢n báº±ng nghiÃªm trá»ng.  
- VÃ¬ tháº¿, **mÃ´ hÃ¬nh tuyáº¿n tÃ­nh TF-IDF + LR láº¡i hiá»‡u quáº£ hÆ¡n**.  

---

## **7. Nháº­n xÃ©t & hÆ°á»›ng má»Ÿ rá»™ng**
### Æ¯u Ä‘iá»ƒm:
- TF-IDF + LR: nhanh, hiá»‡u quáº£, Ã­t cáº§n tÃ i nguyÃªn.  
- LSTM: tiá»m nÄƒng vá»›i dá»¯ liá»‡u lá»›n, cÃ³ thá»ƒ há»c Ä‘Æ°á»£c ngá»¯ cáº£nh dÃ i.

### Háº¡n cháº¿:
- LSTM yÃªu cáº§u dá»¯ liá»‡u phong phÃº, embedding phÃ¹ há»£p.  
- Word2Vec trung bÃ¬nh máº¥t toÃ n bá»™ thÃ´ng tin thá»© tá»±.  

### HÆ°á»›ng má»Ÿ rá»™ng:
- Thu tháº­p thÃªm dá»¯ liá»‡u tháº­t tá»« **HWU64 dataset**.  
- Fine-tune embedding pretrained lá»›n hÆ¡n nhÆ° **GloVe** hoáº·c **BERT embeddings**.  
- DÃ¹ng **Bidirectional LSTM** hoáº·c **GRU** Ä‘á»ƒ cáº£i thiá»‡n hiá»‡u nÄƒng.  
- So sÃ¡nh thÃªm vá»›i mÃ´ hÃ¬nh **Transformer (BERT base)**.

---

## **Káº¿t luáº­n cuá»‘i cÃ¹ng**
> Trong bá»‘i cáº£nh dá»¯ liá»‡u nhá» vÃ  Ä‘Æ¡n giáº£n, **TF-IDF + Logistic Regression** vÆ°á»£t trá»™i hÆ¡n háº³n cÃ¡c mÃ´ hÃ¬nh há»c sÃ¢u.  
> Khi dá»¯ liá»‡u tÄƒng, LSTM sáº½ phÃ¡t huy sá»©c máº¡nh há»c chuá»—i, Ä‘áº·c biá»‡t khi dÃ¹ng embedding pretrained cháº¥t lÆ°á»£ng cao.
